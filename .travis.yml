#specify docker as dependency
#build test version of React + test
#build prod versions of all project
#push all to docker hub
#tell EB to update

sudo: required
language: generic

services:
  - docker

before_install:
  - docker build -t nathanwkwong/react-test -f ./client/Dockerfile.dev ./client

script: #exit other than 0 -> fail
  - docker run -e CI=true nathanwkwong/react-test npm test

after_success:
  - docker build -t nathanwkwong/multi-client ./client
  - docker build -t nathanwkwong/multi-nginx ./nginx
  - docker build -t nathanwkwong/multi-server ./server
  - docker build -t nathanwkwong/multi-worker ./worker
  # Log in to the docker CLI
  - echo "$DOCKER_PASSWORD" | docker login -u "$DOCKER_ID" --password-stdin
  # Take those images and push them to docker hub
  - docker push nathanwkwong/multi-client
  - docker push nathanwkwong/multi-nginx
  - docker push nathanwkwong/multi-server
  - docker push nathanwkwong/multi-worker
deploy:
  edge: true
  provider: elasticbeanstalk
  region: ap-northeast-2
  app: multi-docker
  env: MultiDocker-env
  bucket_name: elasticbeanstalk-ap-northeast-2-403354037318
  bucket_path: docker-multi
  on:
    branch: master
  access_key_id: $AWS_ACCESS_KEY
  secret_access_key: $AWS_SECRET_KEY

#Dockerrun.aws.json, container definition, pull docker from docker hub -> ...
#Elastic container service task definition: instructions on how to run a single container
#https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definitions.html

# {
#   "name": "client", #name of container in dashboard
#   "image": "nathanwkwong/multi-client", #image to use
#   "hostname": "client", #service name, can also be accessed by nginx default.conf; optional field
#   "essential": false, #false by default - no as essential; 
#       true - crash -> close all other containers; 
#       at least on as essential
#   "memory": 128
# },


    # {
    #   "name": "nginx",
    #   "image": "nathanwkwong/multi-nginx",
    #   "hostname": "nginx",
    #   "essential": true,
    #   "portMappings": [
    #     {
    #       "hostPort": 80, #open a port from the machine
    #       "containerPort": 80 #map to the container; 80 as the default port listen inside the container
    #     }
    #   ],
    #   "links": ["client", "server"], #name; unidirectional
    #   "memory": 128
    # }

# AWS Elastic Cache - redis
# - auto create and maintains Redis instances
# - easy to scale + built in logging + maintenance
# - better security, easier to migrate off of EB with(because of decoupling)

#AWS Relational Data Service (RDS) - postgres
# - ...
# - auto backups and rollbacks

#region, one 'default' VPC per region
#virtual private cloud connecting aws services
#create Security Group (Firewall Rules)
#sources internet traffic can connect services inside the VPC

#e.g. EB instance -> open :80 source 0.0.0.0/0 (in bound rules to all)
#source 0.0.0.0/0 (outbound rules to all) 

#setting: (EB, RDS, EC)allow any traffic from any other aws service that has this security group

#elasticahe: cluster
# un check enabled
#node type: t2.micro
#replicase: 0

#subnet group
#name: redis-group
#VPC ID: default
#Security groups: default

#create security group
# group name: 
# description: 
# VPC: default

#inbound rules: TCP, port range source -> security group
#outbound rules

#set services' security group:
#elasticache: actions -> modify -> select multi-docker security group
#no need maintenance window
 
#rds -> instnaces -> select db -> modify -> security group 

#ebs -> configuration -> instances -> ec2 security groups

#connect all aws services:
# ebs -> configuration -> software -> add
# elasticache: REDIS_HOST - primary endpoint(no need port)
# available to all containers

# env variables for containers auto mapped from docker-compose.yml to dockerrun.aws.json

#IAM -> create IAM user -> allow all ECS related service(at most 10) -> add AWS access and secret KEY to traivs